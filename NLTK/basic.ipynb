{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "# nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "str= \"\"\"The NLTK (Natural Language Toolkit) is a popular Python library used for working with human language data, also known as natural language processing (NLP). \n",
    "It provides various tools and resources for tasks such as tokenization, stemming, tagging, parsing, and more.\n",
    "NLTK is widely used by researchers, developers, and practitioners in the field of NLP for tasks ranging from text analysis to machine learning.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=word_tokenize(str)\n",
    "b=sent_tokenize(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word tokens:\n",
      "['Tokenization', 'is', 'a', 'crucial', 'step', 'in', 'natural', 'language', 'processing', '.', 'It', 'breaks', 'down', 'text', 'into', 'smaller', 'units', 'called', 'tokens', '.', 'These', 'tokens', 'can', 'be', 'words', ',', 'sentences', ',', 'or', 'even', 'subwords', '.']\n",
      "\n",
      "Sentence tokens:\n",
      "['Tokenization is a crucial step in natural language processing.', 'It breaks down text into smaller units called tokens.', 'These tokens can be words, sentences, or even subwords.']\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# nltk.download('punkt')  # Download the necessary resources for tokenization\n",
    "\n",
    "# Sample text for tokenization\n",
    "text = \"Tokenization is a crucial step in natural language processing. It breaks down text into smaller units called tokens. These tokens can be words, sentences, or even subwords.\"\n",
    "\n",
    "# Word tokenization\n",
    "words = word_tokenize(text)\n",
    "print(\"Word tokens:\")\n",
    "print(words)\n",
    "\n",
    "# Sentence tokenization\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"\\nSentence tokens:\")\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'fli', 'happili', 'maximum', 'cat']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "words = [\"running\", \"flies\", \"happily\", \"maximum\", \"cats\"]\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "print(stemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'fly', 'happily', 'maximum', 'cat']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to noun\n",
    "\n",
    "\n",
    "words = [(\"running\", \"VBG\"), (\"flies\", \"NNS\"),\n",
    "         (\"happily\", \"RB\"), (\"maximum\", \"JJR\"), (\"cats\", \"NNS\")]\n",
    "lemmatized_words = [lemmatizer.lemmatize(\n",
    "    word, get_wordnet_pos(pos)) for word, pos in words]\n",
    "\n",
    "print(lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Download NLTK data (you only need to do this once)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Sample text for tokenization\n",
    "sample_text = \"NLTK is a powerful library for natural language processing. It provides easy-to-use interfaces to over 50 corpora and lexical resources.\"\n",
    "\n",
    "# Tokenize into words\n",
    "words = word_tokenize(sample_text)\n",
    "\n",
    "# Tokenize into sentences\n",
    "sentences = sent_tokenize(sample_text)\n",
    "\n",
    "# Display the results\n",
    "print(\"Original Text:\")\n",
    "print(sample_text)\n",
    "\n",
    "print(\"\\nTokenized Words:\")\n",
    "print(words)\n",
    "\n",
    "print(\"\\nTokenized Sentences:\")\n",
    "print(sentences)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
